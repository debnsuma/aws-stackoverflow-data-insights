{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ac1d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-35.us-east-2.compute.internal:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0-amzn-1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa66c0eaad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bced328",
   "metadata": {},
   "source": [
    "## Processing `Comments.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbdfb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType, LongType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682af470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path \n",
    "dataset_bucket = 's3://stackoverflow-dataset-2023/dataset/raw/2023'\n",
    "dataset_comments = f\"{dataset_bucket}/Comments.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba507144",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(dataset_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638b9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_parser(row):\n",
    "    \n",
    "    fields = [\n",
    "                \"Id=\",\n",
    "                \"PostId=\",\n",
    "                \"Score=\",\n",
    "                \"Text=\",\n",
    "                \"CreationDate=\",\n",
    "                \"UserDisplayName=\",\n",
    "                \"UserId=\",\n",
    "                \"ContentLicense=\"\n",
    "            ]\n",
    "    \n",
    "    row_field = dict.fromkeys(fields, None)\n",
    "    row_list = [ i.strip() for i in row.split('\"')[:-1] ]\n",
    "    \n",
    "    for i in range(0, len(row_list), 2):\n",
    "        if row_list[i] == 'CreationDate=':\n",
    "            row_field[row_list[i]] = datetime.strptime(row_list[i+1], \"%Y-%m-%dT%H:%M:%S.%f\")        \n",
    "        else:\n",
    "            row_field[row_list[i]] = row_list[i+1]\n",
    "        \n",
    "    \n",
    "    return tuple(row_field.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57413bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_rdd = rdd.map(lambda row: row.strip()) \\\n",
    "   .filter(lambda row: row.startswith(\"<row\")) \\\n",
    "   .map(lambda row: row[4:-3]) \\\n",
    "   .map(lambda row: row.strip()) \\\n",
    "   .map(row_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45e44f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88222951"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f28370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the DataFrame\n",
    "comments_schema = StructType([\n",
    "    StructField(\"Id\", StringType()),\n",
    "    StructField(\"PostId\", StringType()),\n",
    "    StructField(\"Score\", StringType()),\n",
    "    StructField(\"Text\", StringType()),\n",
    "    StructField(\"CreationDate\", TimestampType()),\n",
    "    StructField(\"UserDisplayName\", StringType()),\n",
    "    StructField(\"UserId\", StringType()),\n",
    "    StructField(\"ContentLicense\", StringType())\n",
    "])\n",
    "\n",
    "# Convert the RDD to a DataFrame\n",
    "df = parsed_rdd.toDF(comments_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae23a1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- PostId: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- CreationDate: timestamp (nullable = true)\n",
      " |-- UserDisplayName: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ContentLicense: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337b3c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------------------+--------------------+---------------+-------+--------------+\n",
      "| Id|PostId|Score|                Text|        CreationDate|UserDisplayName| UserId|ContentLicense|\n",
      "+---+------+-----+--------------------+--------------------+---------------+-------+--------------+\n",
      "| 10| 45651|    6|It will help if y...|2008-09-06 13:38:...|           null|    242|  CC BY-SA 2.5|\n",
      "| 12| 47428|    3|One of the things...|2008-09-06 13:51:...|           null|   4642|  CC BY-SA 2.5|\n",
      "| 14| 47481|    0|I agree, both Cod...|2008-09-06 14:15:...|           null|   4642|  CC BY-SA 2.5|\n",
      "| 15| 47373|    0|Just wanted to me...|2008-09-06 14:30:...|           null|   2495|  CC BY-SA 2.5|\n",
      "| 16| 47497|    1|Indeed, the only ...|2008-09-06 14:42:...|           null|   4642|  CC BY-SA 2.5|\n",
      "| 18| 47513|    2|This advice goes ...|2008-09-06 15:02:...|           null|   2515|  CC BY-SA 2.5|\n",
      "| 19| 47466|    2|It was bad when p...|2008-09-06 15:11:...|           null|   2515|  CC BY-SA 2.5|\n",
      "| 20|  1517|    0|In the interests ...|2008-09-06 15:44:...|           null|    199|  CC BY-SA 2.5|\n",
      "| 21| 47527|    1|The Digg link was...|2008-09-06 16:00:...|           null|    658|  CC BY-SA 2.5|\n",
      "| 22| 47626|    0|concat infact doe...|2008-09-06 16:46:...|           null|    292|  CC BY-SA 2.5|\n",
      "| 25| 47626|   10|infact it does. L...|2008-09-06 17:37:...|           null|   4213|  CC BY-SA 2.5|\n",
      "| 26| 47464|    0|Yep. I have been ...|2008-09-06 19:15:...|           null|2353001|  CC BY-SA 2.5|\n",
      "| 27| 47624|    7|&quot;Currently +...|2008-09-06 19:25:...|           null|   4064|  CC BY-SA 2.5|\n",
      "| 30| 36050|    0|I am assuming tha...|2008-09-06 20:14:...|           null|   4906|  CC BY-SA 2.5|\n",
      "| 33| 47513|    1|Bloats the HTML &...|2008-09-06 20:33:...|           null|   4906|  CC BY-SA 2.5|\n",
      "| 41| 47885|   18|I don't think tha...|2008-09-06 22:32:...|           null|   4213|  CC BY-SA 2.5|\n",
      "| 44| 47885|    5|Maybe you should ...|2008-09-06 22:42:...|           null|   1597|  CC BY-SA 2.5|\n",
      "| 48| 47895|    0|Can you be more s...|2008-09-06 23:00:...|           null|   4213|  CC BY-SA 2.5|\n",
      "| 52| 47937|    1|Thanks! That's wh...|2008-09-06 23:18:...|           null|     91|  CC BY-SA 2.5|\n",
      "| 59| 47885|   12|It's still very u...|2008-09-07 00:13:...|           null|   2915|  CC BY-SA 2.5|\n",
      "+---+------+-----+--------------------+--------------------+---------------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a936c05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88222951"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df \\\n",
    "    .withColumn('Id', F.col('Id').cast('int')) \\\n",
    "    .withColumn('PostId', F.col('PostId').cast('int')) \\\n",
    "    .withColumn('Score', F.col('Score').cast('int')) \\\n",
    "    .withColumn('UserId', F.col('UserId').cast('int')) \n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7654e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path \n",
    "output_bucket = 's3://stackoverflow-dataset-2023/dataset/raw-processed/2023'\n",
    "output_folder_name = f\"{output_bucket}/Comments-parquet\"\n",
    "\n",
    "# save dataframe as csv\n",
    "df.write \\\n",
    "  .format('parquet') \\\n",
    "  .option('header', True) \\\n",
    "  .mode('overwrite') \\\n",
    "  .save(output_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec480d",
   "metadata": {},
   "source": [
    "## Verifying the data by reading from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a593cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "         .option(\"header\", True) \\\n",
    "         .option(\"inferSchema\", True) \\\n",
    "         .parquet(output_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d502d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88222951"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd828c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
